{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38332bitchatanalysisenvvenv1323ebea47c2422680e538002ca4b037",
   "display_name": "Python 3.8.3 32-bit ('ChatAnalysisEnv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data set.\n",
    "gameDf = pd.read_csv('gameDf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The csv has the list of chat messages as a single string. This function recovers the python list.\n",
    "gameDf['chatsclean'] = gameDf['chatsclean'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoW encoding, text has already been processed.\n",
    "vectorizer = CountVectorizer(tokenizer=lambda x: x, preprocessor=lambda x: x,lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating machine learning matricies and performing train-test split for validation.\n",
    "X = vectorizer.fit_transform(gameDf['chatsclean'].tolist()).toarray()\n",
    "y = gameDf['result'].to_numpy()\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X,y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GridSearchCV(estimator=RandomForestClassifier(class_weight='balanced'),\n             param_grid={'max_features': ['sqrt', 'log2'],\n                         'min_samples_leaf': [2, 4, 8, 16],\n                         'n_estimators': [64, 128, 256, 512, 1024]})"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Creating parameter space and fitting models using grid search.\n",
    "paramGrid = {'n_estimators': [2 ** n for n in range(6,11)],  \n",
    "              'max_features': [\"sqrt\",\"log2\"],\n",
    "              'min_samples_leaf': [2 ** n for n in range(1,5)]}  \n",
    "grid = GridSearchCV(RandomForestClassifier(class_weight=\"balanced\"), paramGrid, verbose = 0) \n",
    "grid.fit(XTrain,yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "RandomForestClassifier(class_weight='balanced', max_features='sqrt',\n                       min_samples_leaf=2, n_estimators=256)"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Fitting the best model found in grid search to the data set.\n",
    "grid.best_estimator_.fit(XTrain,yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.574468085106383\n0.7357142857142858\n0.5957446808510638\n              precision    recall  f1-score   support\n\n           0       0.55      0.52      0.54        42\n           1       0.63      0.65      0.64        52\n\n    accuracy                           0.60        94\n   macro avg       0.59      0.59      0.59        94\nweighted avg       0.59      0.60      0.59        94\n\n"
    }
   ],
   "source": [
    "# Printing all metrics of interest: fraction of \"win\" predictions, train/test accuracy, and f1-score.\n",
    "print(sum(grid.best_estimator_.predict(XTest))/len(grid.best_estimator_.predict(XTest)))\n",
    "print(grid.best_estimator_.score(XTrain,yTrain))\n",
    "print(grid.best_estimator_.score(XTest,yTest))\n",
    "print(classification_report(yTest, grid.best_estimator_.predict(XTest))) "
   ]
  }
 ]
}