{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38332bitchatanalysisenvvenv1323ebea47c2422680e538002ca4b037",
   "display_name": "Python 3.8.3 32-bit ('ChatAnalysisEnv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from IPython.display import clear_output\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import ast\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "from config import riot_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Joining together chat messages if they occured within 10 seconds. This is only needed\n",
    "# for the Google sentiment analysis, which considers context.\n",
    "directory = 'chatLogs'\n",
    "gameID = []\n",
    "chats = []\n",
    "for filename in os.listdir(directory):\n",
    "    data = json.load(open(os.path.join(directory,filename)))\n",
    "    gameID.append(filename.split(\"Game \")[1][:-5])\n",
    "    messageList = []\n",
    "    i = 0\n",
    "    textsCount = len(data['text'])-1\n",
    "    while i <= textsCount:\n",
    "        if i == textsCount:\n",
    "            messageList.append(data['text'][i]['chat'])\n",
    "            i += 1\n",
    "        else:\n",
    "            if (data['text'][i+1]['gameTime'] - data['text'][i]['gameTime']) < 10000000:\n",
    "                j = i\n",
    "                message = data['text'][j]['chat']\n",
    "                while j != textsCount and (data['text'][j+1]['gameTime'] - data['text'][j]['gameTime']) < 10000000:\n",
    "                    message += (\" \" + data['text'][j+1]['chat'])\n",
    "                    j += 1\n",
    "                messageList.append(message)\n",
    "                i = j + 1\n",
    "            else:\n",
    "                messageList.append(data['text'][i]['chat'])\n",
    "                i += 1\n",
    "    chats.append(messageList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting results into a dataframe.\n",
    "gameDfRaw = pd.DataFrame()\n",
    "gameDfRaw['gameid'] = gameID\n",
    "gameDfRaw['chats'] = chats\n",
    "gameDfRaw['chatsflat'] = gameDfRaw['chats'].apply(lambda x: [word for i in [line.split() for line in x] for word in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the nltk stopwords list to remove punctuation and manually add some stopwords\n",
    "# I noticed that do not appear.\n",
    "stops = stopwords.words('english')\n",
    "stops.append(\"u\")\n",
    "stops.append(\"ur\")\n",
    "stops.append(\"im\")\n",
    "stops = [re.sub(\"[^0-9a-z]+\",\"\",w) for w in stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting all preprocessing steps into one function to prepare for machine learning.\n",
    "# If I am able to get more data, I will probably replace these steps with a pipeline and not use pandas.\n",
    "def preprocessing(flat):\n",
    "    gameInitialisms = {\"gg\":\"good game\",\"mb\":\"my bad\",\"gj\":\"good job\",\"lol\":\"laugh out loud\"}\n",
    "    result1 = [w.lower() for w in flat]\n",
    "    result2 = [re.sub(\"[^0-9a-z]+\",\"\",w) for w in result1]\n",
    "    for i in range(len(result2)):\n",
    "        if result2[i] in gameInitialisms.keys():\n",
    "            result2[i] = gameInitialisms[result2[i]]\n",
    "    result3 = [word for i in [line.split() for line in result2] for word in i]\n",
    "    result4 = [w for w in result3 if w not in stops]\n",
    "    result5 = [w for w in result4 if len(w)>0]\n",
    "    return result5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Applying the preprocessing function. The text will still need to be encoded, which will be done in\n",
    "# the model notebooks in case I want to try different encoding methods in the future.\n",
    "gameDfRaw['chatsclean'] = gameDfRaw['chatsflat'].map(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uncomment to query Riot Games API for match results.\n",
    "\n",
    "# directory = 'chatLogs'\n",
    "# for filename in os.listdir(directory):\n",
    "#     if filename[-5:] == \".json\":\n",
    "#         clear_output()\n",
    "#         match = filename.split(\"Game \")[1][:-5]\n",
    "#         print(match)\n",
    "#         r = requests.get(f\"https://na1.api.riotgames.com/lol/match/v4/matches/{match}?api_key={riot_api_key}\")\n",
    "#         print(r.status_code)\n",
    "#         json.dump(r.json(),open(f\"API/{match}.json\",\"w\"))\n",
    "#         time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extracting match results from the response jsons. Note that custom matches do not return participant\n",
    "# identities. I only had one custom match in the data set so I manually removed it, but it will need to\n",
    "# be handled if upsizing.\n",
    "directory = 'API'\n",
    "gameVerification = []\n",
    "gameResult = []\n",
    "for filename in os.listdir(directory):\n",
    "    result = json.load(open(os.path.join(directory,filename)))\n",
    "    for participantIdentity in result['participantIdentities']:\n",
    "        if participantIdentity['player']['summonerName']==\"Shawner\":\n",
    "            myid = participantIdentity['participantId']\n",
    "    for participant in result['participants']:\n",
    "        if participant['participantId']==myid:\n",
    "            gameVerification.append(filename[:-5])\n",
    "            gameResult.append(participant['stats']['win'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting results into a dataframe to merge with the texts.\n",
    "resultDf = pd.DataFrame()\n",
    "resultDf['gameid'] = gameVerification\n",
    "resultDf['result'] = gameResult\n",
    "gameDfRes = gameDfRaw.merge(resultDf, on=\"gameid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final processing. Removing matches without text, and converting \"True/False\" to \"1/0\" for the ML models.\n",
    "gameDfRes['result'] = gameDfRes['result'].map(lambda x: x*1)\n",
    "gameDfClean = gameDfRes[gameDfRes['chatsclean'].map(len) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting data set with unbalanced classes for sentiment analysis.\n",
    "gameDfClean.to_csv(\"gameDfClean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancing the classes.\n",
    "winDf = gameDfClean[gameDfClean['result']==1]\n",
    "lossDf = gameDfClean[gameDfClean['result']==0]\n",
    "gameDf = pd.concat([winDf.sample(n=187,random_state=0),lossDf],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting data set with balanced classes for machine learning.\n",
    "gameDf.to_csv(\"gameDf.csv\")"
   ]
  }
 ]
}